# CDC(Change Data Capture)

CDC는 Change Data Capture의 약자로, 운영중인 DB의 정보를 “옮길 때” 주로 사용한다. 데이터의 전파, 복제, 마이그레이션 과정에서 Source DB의 변화를 변경 로그를 통해 추출해 DB가 멈추는 시간을 줄이고, 반영되지 못하는 정보를 추적한다.

<br>

![image](https://github.com/10000-Bagger/free-topic-study/assets/71186266/9ebcbec4-fb76-4ff9-aa58-9b1a70d2e5e0)

<br>

금융권에서는 보통 DB를 목적에 따라 완전히 분리해 사용한다. 
금융업 종사자와 고객이 만드는 데이터들이 DB에 쌓이면, 주기적으로 “정보계”라는 기관내 주요 정보들이 모이는 DB로 옮긴다.

한 달에 한 번, 일주일에 한 번, 혹은 실시간으로 데이터는 전파되는데, 보통 밤 11시 55분 부터 12시 극초반까지 “점검 중입니다”와 같은 메시지와 함께 송금이 막히는 은행 서비스가 있다면, 아마 데이터를 옮기는 작업을 위해 잠시 멈춰둔 것이다.

<br>

이렇게 데이터를 옮기는 과정에서 주로 사용하는 기술이 CDC이다. 

이제 CDC에 대해 좀 더 알아보자.

# 1. CDC 이전의 방식

CDC를 사용하기 이전엔, 평범하게 데이터를 추출해서 전송했다. 각종 데이터, 스키마, 인덱스, 프로시저 등을 파일로 추출해 목적지 DB에 전달했다. 이 경우 몇 가지 문제가 발생할 수 있었다.

<br>

#### 1. 추가 변경의 반영이 어렵다 - Down Time의 존재

데이터가 방대할 수록 추출하는 시간이 길어진다. 이 경우 데이터를 추출하는 동안 발생하는 변화들은 추적이 어려운데, 기존엔 DB와 연결된 서비스들을 그냥 닫아 버렸다고 한다. 유저 접근을 그냥 막아버려서 데이터가 추가로 쌓이는 것을 막아버린다. 

이러한 시간을 Down Time은이라고 부르는데, DB가 방대할 수록 길어진다. 예전 증권의 경우 장 마감 시간이 있기에 나름 편하게 Down Time을 만들 수 있었으나, 뱅킹이나 페이먼츠 쪽에선 쉽지 않다.

<br>

#### 2. 실시간 반영의 부하

기존 방식대로는 실시간 반영의 부하가 크다. 원천 시스템에 Trigger를 걸어 처리하는 방법을 사용하기도 했었지만, 부하가 크고, 장애 추적이 어렵다고 한다. 데이터 전파 주기가 짧은 경우 DB에 여러 부담을 주었다.

<br>

#### 3. 변경분 만을 구분하기가 어렵다. 

특정 시점으로 부터의 변경분을 빠르게 파악하기가 쉽지 않다.

이로 인해 역방향 마이그레이션과 같은 경우 문제가 발생할 수 있다.

만약 DB의 마이그래이션 이후 Target DB에 문제가 생겨 Rollback을 하는 경우를 생각해보자. 이전에 사용중이던 Source DB를 다시 사용하기 위해선, 마이그레이션 이후 추가로 쌓인 정보들이 동기화 되어 있어야 하는데, 기존의 방법으로는 추가적으로 쌓인 데이터만을 선별하는게 어렵기 때문에 또 길고 괴로운 Down Time을 만들어 내야 한다.

<br>

사실 최신 클라우드 서비스를 이용한다면 앞서 언급한 데이터의 전파, 복제, 마이그레이션은 그리 어렵지 않다고 한다. 사실 이러한 고민들은 전세계 모든 서비스들이 공통으로 하는 고민이고, 많은 솔루션들이 개발되어있다. 하지만 금융권 서비스들은 검증된 서비스만을 사용하고 싶어하고, 클라우드에 데이터를 올리는 것을 보통 꺼린다고 한다.

<br>

# 2. CDC

CDC는 앞서 언급한 문제들을 해결할 수 있다. 

CDC는 말 그대로 변경사항을 로그로써 “Capture”해 DB의 변화를 추적한다. 

아래 그림을 통해 CDC의 과정을 살펴보자. 

<br>

![image](https://github.com/10000-Bagger/free-topic-study/assets/71186266/3da7d660-cf0f-4027-a762-5bfe3b5d470a)

<br>

1번 과정은 Data를 옮기기 위해 파일로 추출해내는 과정이다. 
그리고 이 때 부터 변화를 Log로 수집한다. <br> <br>

이후 추출한 파일을 전송하고, Target DB에 저장한다. (2, 3 과정)
그리고 그동안 발생한 로그들을 통해 변경 사항을 확인하고, 변경분을 마저 반영한다. 
(DB Time 1 ~ 6) <br> <br>

이렇게 Down Time을 없애면서, 추가 변경분을 쉽게 파악해 DB 데이터를 옮길 수 있다. <br> <br>
앞서 언급한 역 마이그레이션 문제시 아래 그림에 추가된 6번 과정과 같이 추가분만을 반영하면 된다. 로그만을 위한 서버를 보통 따로 관리하면서, 변경분의 파악을 DB가 하지 않아도 되서 좀 더 쉽고 빨라진다. 

<br>

![image](https://github.com/10000-Bagger/free-topic-study/assets/71186266/fc21b5ec-8ee7-46e3-9f74-58df1efcd0e0)

<br>

이러한 CDC를 통해 이기종간 데이터 마이그레이션, 전파, 복제 등을 쉽고 적은 부하로 해낼 수 있다.

끝~

AWS에서 비슷하게 데이터 전파시켜주는 서비스로는 Glue가 있다고 함.

[AWS Glue란 무엇인가요? - AWS Glue](https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html#glue-features-summary)

<br>

## Reference
- https://www.samsungsds.com/kr/insights/migration_cdc.html
- https://www.megazone.com/armiq_series3/
- https://www.datanet.co.kr/news/articleView.html?idxno=155922
