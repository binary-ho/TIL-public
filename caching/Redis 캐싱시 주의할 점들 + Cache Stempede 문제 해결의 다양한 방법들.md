# Redis 캐싱시 주의할 점들 + Cache Stempede 문제 해결의 다양한 방법들
캐시 데이터는 결국 자주 조회되는 데이터 혹은 조회 비용이 비싼 데이터들을 캐시에 유지할 수 있으면 된다. <br>
문제는 용량은 한정되어 있다는 것. 용량은 한정되어 잇는데, 캐시에 데이터는 계속 추가되다보니, **만료시간을 두고** 데이터를 삭제하거나, 꽉차게 되는 경우 어떤 캐시를 남기고 **어떤 캐시를 지울지에 대한 전략인 maxmemory-policy를 잘 세워야 한다.** <br> <br>

이러한 전략을 세우는 것은 중요하다. 또 캐시 데이터가 언젠가 삭제된다는 점을 고려한다면 여러가지 추가로 생각해볼 문제가 있다. 가령 캐시 설계에 따라 데이터 삭제의 소요 시간이 너무 오래 걸릴 수도 있다는 점이나, 섣불리 자주 조회되는 캐시 데이터를 지워버리면 Cache Stampede, Thundering Herd 등의 문제가 발생할 수 있다. <br> <Br>

오랜만에 데이터를 캐싱할 때 고려해야 할 점들을 간단히 정리해보자.

[목차]
1. 캐싱 전략
2. 만료 시간
3. Eviction 전략
4. Cache Stampede
5. Failover는 무조건 DB에?



# 1. 캐싱 전략
캐시 데이터를 어떻게 저장하고 어떻게 읽을 것인가?

## 1.1 캐시 읽기 전략
### 1.1.1 Look Aside
![Pasted image 20230925203350](https://github.com/10000-Bagger/free-topic-study/assets/71186266/60e95e71-ba80-42e5-b9e2-d91c11e31a75)

<br>

캐시 먼저 확인하는 전략. MISS인 경우 DB를 통해 데이터를 가져온다.

- 장점: 빠른 응답 속도, 캐시에 장애가 생겨도 DB 조회하면 그만임.
- 단점
    1. DB에 데이터가 변경되면 캐시 데이터와 잠깐 차이가 생길 수 있음 -> 캐시 불일치 문제
    2. 캐시에 장애가 생기는 순간 DB로 부하가 한번에 몰릴 수 있음 -> Thundering Herd 문제 발생
    3. 캐시에 조회할 데이터가 크게 바뀌는 순간이 오는 경우, 초기 데이터를 적절히 Warming 해줘야함. **ex) 공연 티케팅 오픈을 앞두고 있는 경우 해당 공연 데이터를 저장하면 좋을 것이다..**

## Thundering Herd 문제 해결 사례
## 1.2 캐시 쓰기 전략
캐시를 언제 어떻게 저장할 것이냐는 캐시 불일치 문제와 직결되기 때문에 중요한 문제이다.


### 1.2.1 Write Through
![Image](https://github.com/user-attachments/assets/cea4a7bb-0272-49b0-bcd0-6d92b75c51b5)



**데이터베이스에 업데이트 할 때마다 캐시에도 데이터를 업데이트 하는 전략** <br>

- 장점: 캐시는 항상 최신 데이터를 가지고 있을 수 있다.
- 단점
  - 데이터를 두군데 써야 하기 때문에, 추가 부하 발생.
  - 캐시는 자주 조회될 데이터가 저장 되어야 하는데, 이 경우엔 모든 데이터가 저장되어 버릴 수도 있음. -> 만료 시간이나 정책을 적절하게 잘 설정해야 한다.

### 1.2.2 Cache Invalidate
DB에서 어떤 값을 업데이트 할 때마다 Cache에 있는 데이터를 업데이트 하는게 아니라, 그냥 삭제해 버린다. TODO: 언제 쓰면 좋은건지 찾아보기.. 자주 쓰는 데이터이면 손해인거 같은데

### 1.2.3 Write Behind (Write Back)
**캐시에 먼저 쓰고, 나중에 DB에 쓰는 정책** <br>
- 장: 쓰기 부하를 크게 완화 시킬 수 있고, 캐시 데이터가 오히려 DB 데이터 보다 최신이다.
- 단
  - 중요한 데이터의 경우 캐시 데이터가 터지면 다 터지는 거.. 백업을 하던, HA를 하던 결국 리스크가 있으니, 유실 감당 가능한 데이터만 이렇게 다뤄야 한다.
  - 원래 DB에서 실시간으로 집계하던 데이터였다면 실시간 집계가 안되니까 따로 처리가 필요.


# 2. 만료시간
Redis는 간편하게 특정 키에 대한 TTL을 설정할 수 있다. <br>
`EXPIRE` 커멘드로 간단하게 설정할 수 있으며, 데이터를 저장할 때는 `EX` 옵션으로 저장과 동시에 설정할 수도 있다. <br>


### 만료 이후, 삭제는 어떻게 될까?
레디스는 key에 설정한 만료시간이 지나도 바로 데이터를 삭제하지 않는다. 
- 장점: 이는 삭제하는데 필요한 리소스를 줄이는 효과가 있다. 
- 단점: 하지만, 최악의 경우 전체 메모리의 1/4가 이미 만료된 키일 수 있다고 한다.  

<br>

아래 2가지 방법으로 삭제된다.
1. `active 방식`: **TTL이 설정된 데이터 중 20개를 랜덤으로 뽑아서 만료된 키를 삭제한다. 이 행위를 1초에 10번씩이나 수행한다고 한다.** <br> 만료된 키를 삭제한 다음에 25% 미만의 키가 삭제된다면, 그 안에서 한번 더 만료시간을 확인한다. 25% 이상 삭제했다면 다시 20개의 새로운 키를 뽑아 만료시간을 확인한다.
2. `passive 방식`: **클라이언트가 데이터에 접근했을 때, 만료시간이 지났다면 삭제한다.** 아마 영원히 접근되지 않는 데이터도 있을텐데, 그런 데이터의 경우 `active 방식`에 의해 지워질 것이다.


# 3. Eviction 전략
Redis에 설정한 메모리 용량을 초과하는 데이터가 저장되는 경우, 어떤 데이터를 삭제할지 결정하기 위해, `maxmemory-policy`를 설정할 수 있다. <Br>
대부분 학부시절 OS수업에서 만나는 반가운 이름들이다.

## 3.1 (기본) Noeviction
기본 전략은 no eviction이다. **용량이 가득찬 경우 기존 데이터를 삭제하지 않고, 새로운 데이터를 거절한다.** <br>
캐시가 가득차더라도 자동으로 삭제되면 안되는 경우 사용할 수 있는 옵션. 보통은 Redis가 관리하지 않고, Application이나 다른 도구로 관리하려 할 때 사용할 수 있겠다.

## 3.2 LRU eviction
**Least Recently Used 는 가장 오래동안 사용되지 않은 데이터를 삭제한다** <br>

오래동안 쓰이지 않은 데이터는 앞으로도 쓰이지 않을 것이라는 가정이 있으면 이 전략을 사용하면 되겠다. 기본적인 전략으로 Redis에서도 "잘 모르겠으면 이 전략 쓰세요"라고 추천하는 전략이다. <br> 

총 2가지 설정값이 있다.
1. `volatile-lru`: 만료 시간이 설정되어 있는 키에 한해 LRU를 적용. **주의할 점은 실수로 캐싱 데이터들에 만료시간을 정해두지 않는 경우 전부 noeviction처럼 취급될 수도 있다.**
2. `allkeys-LRU`: 모든 키에 LRU를 적용 (Redis 왈: 잘 모르겠으면 이거 쓰셈)


## 3.3 LFU eviction
**Least-Frequently Used 자주 사용되지 않은 데이터 부터 삭제하는 전략이다.** 자주 참조되지 않는 데이터는 앞으로도 참조될 확률이 높다면 사용하기에 적합. <br>

1. `volatile-lfu`: **만료시간이 설정되어 있는 키에만 LFU를 적용한다.** 주의할 점은 실수로 캐싱 데이터들에 만료시간을 정해두지 않는 경우 전부 noeviction처럼 취급될 수도 있다.
2. `allkeys-lfu`: 모든 키에 대해 LFU 알고리즘 적용



### LRU, LFU 비교
둘은 비슷하지만 다르다. <br> 
**최근에 자주 사용하지는 않았지만, 옛날에 자주 사용했던 데이터가 있다고 생각해보자. 이 데이터는 LRU에서는 삭제 대상이고, LFU에서는 삭제 대상이 아닐 수 있다.** <br> 
(외우기용: 70년대 인기 가수) 


## 3.4 RANDOM eviction
정말 랜덤으로 삭제한다... LRU, LFU등의 알고리즘을 사용하지 않으므로 eviction 알고리즘 부하가 줄어든다. <br>
뭐 그렇게까진 줄어드는 것은 아니라서 사용하지 않는 것을 권장! <br>
이 옵션도 2가지 설정 값이 있다. `volatile-random`, `allkeys-random`

## 3.5 volatile-ttl
**만료시간이 가장 작은 키를 삭제한다** <br>
삭제시간이 얼마 남지 않은 키를 추출해 삭제하는 옵션

# 4. 캐시 스탬피드 문제
인기있는 캐시가 만료되는 경우, 갑자기 DB에서 같은 데이터를 계속 요청하게 될 것이고, 캐시에 같은 데이터를 여러번 쓸 것이다. (이를 중복 읽기, 쓰기라고 한다) <br>

많은 경우 캐시는 DB에서 조회하는데 오래걸리는 데이터를 빨리 가져오려고 캐싱하는데, **DB에 같은 데이터의 조회 요청을 동시에 여러번 보내고, 또 같은 내용을 여러번 캐시에 쓰므로써 DB와 캐시 둘 다에 부하를 준다.** 이때 DB 장애로 이어지는 경우 사태가 더 심각쓰 <Br>
꼭 인기있는 한개의 데이터가 아니더라도, 여러 데이터의 만료 시간이 동일한 경우, 여러 데이터가 동시에 만료되면 똑같은 문제가 발생할 수도 있다. <br>
캐시 버전의 Thundering Herd.. 어떻게 완화할 수 있을까?

<br>

여러가지 방법이랑 사례를 찾아 보았고, 토스와 라인에서 작성한 아티클을 기반으로 정리해봤다. (래퍼런스는 아래) <br>


1. 여러 데이터의 만료를 대비하는 경우 랜덤 추가 만료 시간을 더해준다.
2. 만료되기 전에 캐시를 업데이트 한다.
3. Lock을 활용해 캐시 Update를 1회로 줄인다. 즉, 캐시 만료시 DB 조회 + 캐시 Write 작업을 한개의 작업 주체만 수행할 수 있게 한다.
4. 애초에 DB에도 없는 데이터라면? -> Null Object 패턴을 활용한다.


## 4.1 추가 만료시간 더하기
이 방법이 제일 중요한 방법이라 위에 둔건 아니고, 다른 방법들이 어느정도 이어져 있어서 맨 위에 뒀다.

## 4.2 만료되기 전에 캐시를 업데이트해 버린다.
결국 이 문제는 Look Aside 패턴에서 캐시의 만료시 발생할 수 있는 문제인 것. <br>

그냥 만료될 일이 없게 하는 방법이 있다.

### 4.2.1 캐시를 조회할 때, 만료시간이 임박한 경우 비동기적으로 DB에서 데이터를 조회해서 업데이트 한다.
![Image](https://github.com/user-attachments/assets/ce6aa525-27b3-4572-b53f-70c88f547b6b)

위 그림처럼 그냥 끊임없이 캐싱이 되도록 하는 것이다.

### 4.2.2 확률적으로 캐시를 업데이트 한다.
개발자를 위한 레디스라는 책에 소개 된 방법이다. <br>
캐시를 조회할 때마다, 일정 확률로 캐시를 업데이트 하도록 알고리즘을 짜는 것이다. <br>
PER(Probabilistic Early Recomputation) 알고리즘이라는 "확률적 조기 재계산 알고리즘"이 있는데, 캐시값 만료 전 언제 DB에 접근해 업데이트 할지 최적의 시간을 계산할 수 있다고 한다. <Br>
만료 시간에 가까울 수록 조회 확률을 높인다.
```
currentTime - (timeToCompute * beta * log(rand())) <= expiry
```
- currentTime: 현재 남은 만료시간
- timeToCompute: 캐시된 값을 다시 계산하는 데 걸리는 시간. DB의 경우 조회 시간일 것이다.
- beta: 일종의 상수인듯..?
- rand(): 0과 1 사이의 랜덤 반환
- expiry: 새로운 만료 시간


위 값을 만족하면 갱신한다. currentTime이 줄어들 수록 expiry보다 작을 확율이 높을 것이다.  <br>
내가 잘못 이해한건지 책이 잘못된건지 수식이 잘못된건지.. expiry가 고정이라면 1회 갱신 이후엔 항상 true아닌가..? 아니면 재계산마다 expiry가 줄어드는건지.. <br>

나중에 알아보자..


<!-- ### 4.2.3 결론
어쨌든 중요한 데이터는 계속 캐싱하게 하는 방법 나쁘지 않은 것 같다. <br> 
두 방법은 뭐가 다를까 고민해 봤는데, 확률적으로 업데이트 하는 것이 더 좋아 보인다. 결국 고정 시간으로 캐시를 조회한다면 적절한 재계산 시간을 정하는게 너무 어려울 것 같다. <br> 
왜냐하면 캐시 데이터마다 조회되는 패턴이 다를거 같은데, 
1. 재계산 시간이 크다: 쓸대없이 자주 업데이트 됨. 알고보니 자주 조회될 데이터가 아닌데도 업데이트 되는 경우가 많을 것이다.
2. 재계산 시간이 적다: 업데이트 해야하는데 적절한 타이밍을 놓칠 수 있음. 예를 들어 3초 조회로 고정해뒀는데, 딱 그 3초만 우연히 조회가 안 된다 -->

### 4.2.3 문제는 있다.
미리 업데이트 해두는 것은 좋다. 하지만 이런 상황을 생각해보자. <br>
엄청 인기있는 key가 있다. 어쩌다 보니 동시 조회가 무지막지하게 들어왔는데, 하필 고정된 재계산 시간 안에 들어와 있고 그 무시무시한 동시 조회가 전부 DB를 향한다. <br>
**결국 이렇게 되면 문제가 해결된건 아니다.** 확률적인 방법이면 훨씬 나을 것이지만 안심할 수는 없다. 여전히 재수가 아주 나쁘면 요청이 몰릴 수 있다. 흑흑 ㅠ.ㅠ <br>

-> 그럼 어케함?

## 4.3 Lock을 활용해 캐시 Update 횟수 줄이기
결국 이 문제는 조회하고 저장하는 데이터는 똑같음에도 DB와 캐시에 쓸대없이 요청이 몰리는 것이 문제다. <br>
**따라서 분산락으로 1개의 실행 주체만 이 작업을 수행하게 제한하자는 아이디어이다.** 


![Image](https://github.com/user-attachments/assets/ce6c564b-d3f6-4cec-841e-d61800ecbf4e)

\<출처: [req-shield로 캐시의 골칫거리 'Thundering Herd 문제' 쉽게 풀기!](https://techblog.lycorp.co.jp/ko/req-saver-for-thundering-herd-problem-in-cache)>


<br> 

알고리즘은 다음과 같다.

[락을 획득한 경우]
1. 캐시에 데이터가 없는 경우 바로 DB를 조회하지 않고, DB 조회 락 획득을 시도한다.
2. 락을 얻은 실행주체는 DB 조회와 캐시 Write를 수행한다.

<br>

[락을 획득하지 못한 경우]
1. 캐시에 데이터가 없는데 락 획득도 실패했다면, 락 타임아웃동안 대기한다.
2. 락 타임아웃 대기동안, 락 타임아웃 이후 캐시를 다시 확인해 데이터가 있는지 확인한다.
3. 데이터가 없는 경우 다시 락 획득을 시도하고, 데이터를 조회한다.
    - 이것은 이전 실행주체가 데이터를 조회하는 것에 실패했다고 판단한 것인데, 조금 구멍은 있어 보인다. 실제로 데이터가 없는 것일 수도 있다. (이떄의 손해는 크다.) 혹은 데이터는 잘 조회하고 락을 릴리즈 했지만, 저장하기 전에 애플리케이션이 STW에 빠졌거나 모종의 이유로 실패 (이때의 손해는 작아 보인다.)

<br>

이런 분산락을 활용하는 아이디어는 캐시 Stempede 문제를 완화할 수 있다. <br>
**다만 실제로 데이터가 없을 때가 걱정이다.** 이 시나리오만 놓고 본다면 실제로 데이터가 없고, 없는 데이터의 요청이 이어지는 경우 모든 요청이 락을 기다리며 DB를 조회할 것이다. (끔찍)

## 4.4 없는 데이터에 대한 Null Object 패턴 적용
Lock을 활용하는 방법들 신나게 적용했지만, **DB에 실제로 없는 데이터에 대한 요청을 대비하지 않는다면 문제가 생긴다.** <br>

없는 데이터를 계속~ 조회하려 한다면 DB로 계~속 요청이 갈건데.. 문제는 Lock이 걸려있기 때문에 순서대로 한번에 한 실행 주체가 조회를 다녀올 것이고 어마무시하게 시간이 많이 들 것이다. <Br>

![Image](https://github.com/user-attachments/assets/5d80a034-72e4-4127-bb91-3325004b4999)

<br>

**이때 Null Object Pattern으로 "없다는 사실"을 캐싱해 문제를 해결할 수 있다.** <br>

### 4.4.1 Null Object Pattern
Null Object Pattern은 어떤 객체를 조회할 때, Null을 반환하는 대신 아무것도 하지 않는 객체 인스턴스를 반환하는 것이다. <br>
예를 들어 Spring의 `Pageable`은 `Unpaeged`라는 널 패턴 객체를 아래와 같이 사용한다.
```java
public interface Pageable {

  /**
   * Returns a {@link Pageable} instance representing no pagination setup.
   *
   * @return
   */
  static Pageable unpaged() {
    // 여기
    return Unpaged.INSTANCE;
  }
}
```


```java

enum Unpaged implements Pageable {

  INSTANCE;

  @Override
  public boolean isPaged() {
    return false;
  }

  @Override
  public Pageable previousOrFirst() {
    return this;
  }

  @Override
  public Pageable next() {
    return this;
  }

  @Override
  public boolean hasPrevious() {
    return false;
  }

  @Override
  public Sort getSort() {
    return Sort.unsorted();
  }

  @Override
  public int getPageSize() {
    throw new UnsupportedOperationException();
  }

  @Override
  public int getPageNumber() {
    throw new UnsupportedOperationException();
  }

  @Override
  public long getOffset() {
    throw new UnsupportedOperationException();
  }

  @Override
  public Pageable first() {
    return this;
  }
}
```


<br>

혹은 마틴 파울러의 조언처럼 `isNull`과 같은 메서드를 넣거나, 아예 이 메서드를 구현하기 위한 인터페이스 `Nullable`과 같은 인터페이스를 만들어 버릴 수도 있다. <br>
단점으로는 실제로 데이터에 문제가 있을 때, 못알아챌 수도 있다.. 그래서 널 객체도 잘 설계해야 한다. <br>

유명 책들이 제안하는 더 다양한 Null Object의 패턴들은 아래 글을 확인해보자.
- [널 오브젝트 패턴 (Null Object Pattern) - 기계인간 John Grib 블로그](https://johngrib.github.io/wiki/pattern/null-object/) 

### 4.4.2 캐시에서의 Null Object 패턴
그래서 캐시에서는 어떻게 데이터를 저장해서 Null Object임을 알리면 좋을지 고민이 된다... <br>
아티클엔 나와있지 않지만 고민해보자면

1. `Null임을 알리는 특별한 문자를 넣는다.`
   - 이 캐시값을 확인하는 코드가 여러 프로젝트에서 작성되어야 한다면, NULL을 대표할 값을 잘 정하고 공유하기 어려울 것 같다. 이 값을 다른 값으로 바꿀 일이 있다면 관련 코드를 싹 바꿔 줘야하니 최악.
   - 정말로 그 값을 가진 데이터가 만들어질 일이 없는지 잘 고민해야 할듯...
2. `아에 isNull 필드를 넣어버린다`
    - 합리적으로 보인다. 다만 저장할 컬럼이 하나 더 늘게 된다. 각종 흑마법으로 용량을 줄일 수는 있을듯..?
3. `아예 키별로 null인 key를 관리하는 자료구조를 준비한다.` 블룸 필터라던지 각종 흑마법을 쓰면 존재 여부를 빠르게 작은 용량으로 관리할 수도 있을듯. 다만 관리할 자료구조가 들어난다..


## Reference
- [(라인) req-shield로 캐시의 골칫거리 'Thundering Herd 문제' 쉽게 풀기!](https://techblog.lycorp.co.jp/ko/req-saver-for-thundering-herd-problem-in-cache)
- [(토스) 캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁](https://toss.tech/article/cache-traffic-tip)
- (책) 개발자를 위한 레디스 <김가림 지음>
- [Null Object Pattern](https://johngrib.github.io/wiki/pattern/null-object/)
