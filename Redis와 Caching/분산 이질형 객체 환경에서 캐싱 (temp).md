
# 분산 이질형 객체 환경에서 캐싱 알고리즘의 설계 및 성능 분석 <반효경>
캐싱의 성능은 캐시 교체 알고리즘에 의해 크게 좌우된다.
캐시 교체 알고리즘은 미래의 참조를 미리 알지 못 하는 상태에서 한정된 캐쉬 공간에 보관하고 있을 객체와 삭제할 객체를 동적으로 결정하는 온라인 알고리즘이다.

광역 분산 환경에서의 캐싱은 근원지 노드의 위치에 따라 인출 비용이 다르기 때문에
전통적인 캐쉬 교체 알고리즘으로는 우수한 성능을 기대하기 어렵다.

전통적인 캐싱 환경에선 단위 객체를 느린 저장장치에서 빠른 저장 장치로 읽어오는 비용이 동일하다.
예를 틀어 페이지는 각각 같은 크기이며, 디스크에서 주 메모리로 읽어오는 비용이 균일하다. 

이러한 차이가 존재하는 환경을 이질형 캐슁 환경이라고 부른다. (non-uniform caching enviornment)

## 2. 캐시 교체 알고리즘들의 목표

기존 동질형 캐싱 환경에서의 주 관심사는, 캐쉬 부재를 줄이는 것이였다.
앞으로 참조될 가능성이 높은 캐시는 남기고 -> <mark style="background: #FF5582A6;">가까운 미래에 참조될 가능성이 가장 낮은 객체를 캐쉬에서 삭재해 cache miss를 줄이는 것이 기존의 캐시 교체 알고리즘의 목표이다</mark>

반면, 이질형 캐싱 환경에서는 객체마다 부재시의 비용이 다르다! <mark style="background: #FF5582A6;">(비용의 합을 줄이는 것이 목표이다.)</mark>
구체적인 예를 보며 생각해보자.

-> 관련 내용은 이 글의 2.2 항목 참고 [링크]()


# 3. 이질형 캐싱 모델의 정의

### 상황
1. 노드가 필요로 하는 객체의 참조 순서는 알려져 있지 않음 (prefetching 불가능)
   오직 현재 요청되는 객체만이 알려져 있다
2. 요청된 객체는 캐쉬에 보관된다.
3. 객체 사이즈 s, 인출 비용 c, 요청 회수 r, 적중 횟수 h
4. 캐쉬 크기는 S
5. 목표 : 참조 요청을 전부 처리했을 떄 인출 비용의 합이 최소가 되도록 한다.


## 3.2 시도들
1. 냅색으로 해결할 수 없을까? -> 냅색은 물건들의 가중치가 전부 알려져 있는데, 이런 이질형 캐슁 환경에서의 교체 알고리즘은 온라인 알고리즘이다. 객체 내용이 변하게 되면서 가중치도 변할 수 있고, 얼마든지 객체가 새로 추가될 수가 있다.
2. 동질형 캐시 환경에서는 미래 참조를 모두 안다고 가정해, 성능 비교 척도로 사용하는 알고리즘이 존재한다. 그걸 ㅇㅇㅇ라고 부르는데, 이질형 캐슁 환경에서는 객체의 미래 참조 순서를 다 안다고 해도 최적의 알고리즘을 찾는 문제가 NP-hard 문제로 알려져 있다

## 3.3 객체들의 가치 평가 방법

캐쉬 교체 알고리즘의 효율성은 결국 "미래의 참조 성향"을 얼마나 잘 예측하는가에 좌우된다.

이질형 환경에서는 미래 참조 성향 예측 외에도 <mark style="background: #FF5582A6;">사이즈와</mark> <mark style="background: #FF5582A6;">인출 비용</mark>에 대한 합리적인 평가를 할 수 있어야 한다.
우수한 알고리즘을 설계하기 위해 고려해야 할 점들은 뭐가 있을까?

1. 과거 참조 기록 평가 (시간 지역성과 인기도)
2. 이질성 고려
3. 통계적인 정보

### 3.3.1 과거 참조 기록에 의한 평가
일반적으로 과거 참조 기록을 통해 객체를 평가한다.
낯선 이야기는 아니다. 익숙한 <mark style="background: #FF5582A6;">LRU와 LFU</mark> 등이 최근 참조 성향과 참조 빈도에 근거해 미래 참조를 예측한다.

이는 아래 두 가지 사실에 의해 입각한 것이다.
1. 최근에 참조된 객체가 다시 참조될 가능성이 높음 (시간 지역성)
2. 참조 횟수가 많은 객체일 수록 또 다시 참조될 가능성이 높음 (객체 인기도)

### 3.3.2 이질성 고려

객체 사이즈와 인출 비용을 고려해야 한다 (계속 반복했던 말)
즉, 객체를 보관하고 있을지에 대한 판단은
<mark style="background: #FF5582A6;">참조 가능성에 대한 가치</mark> 뿐만 아니라, 캐쉬에서 <mark style="background: #FF5582A6;">적중될 경우 실제로 아끼는 비용</mark>을 동시에 고려해야 한다

캐쉬 용량은 정해져 있으므로, 
공간을 적게 차지하면서 절약하는 비용이 큰 객체일수록 각치 평가를 높게 하는 것이 바람직하다

### 3.3.3 통계적인 정보

캐쉬가 사용되는 환경 및 작업 부하의 특성을 분석해 알고리즘에 활용한다.
참조 패턴을 통계적으로 분석하여 사용한다.
잘 활용한다면 prefetching에 사용할 수도 있을 것이다.


# 3.4 기존의 교체 알고리즘들

잘 알려진 알고리즘들이다.
- LRU - Least Recently Used : "최근" 참조된 <mark style="background: #FF5582A6;">시각이 가장 오래된</mark> 객체를 삭제
- LFU - Least Frequently Used : <mark style="background: #FF5582A6;">참조 횟수가 가장 적은 객체</mark>를 삭제
- SIZE : 가장 큰 객체를 삭제
- LLF :(Lowest-Latency-First) : 인출 비용이 가장 적은 객체를 삭제
- LRU-MIN : 필요한 캐시 공간이 s일 떄, 사이즈가 s인 객체 중 <mark style="background: #FF5582A6;">참조 시간이 가장 오래된 객체</mark>를 삭제
- LRV : 참조 빈도에 근거해 다음 참조를 추측하는 P_N -> n번 참조 되었을 때, n+1번 참조될 확률. D(t)는 참조 시간 간격 분포 함수. 가장 최근 참조 이후 t초일 때 재참조될 확률
  
웹 프락시 캐시에서 많이 사용한다. P와 D만 로그를 이용해 잘 추측한다면 쓸만한 알고리즘에 해당한다. 

### 3.4.1 교체 알고리즘들 자료구조

이러한 교체 알고리즘들에서 캐쉬 교체가 필요할 때마다, 모두 그 "가치"를 조사하는 것은 비현실적이다.
따라서 Value의 크기에 따라 보통 힙이나 리스트 구조를 유지한다.
LRU의 경우 단순하게 List형 자료구조를 유지해도 되겠지만,
보통은 힙을 사용하는게 좋다. 힙은 삽입-삭제-재참조 연산을 log_2N만에 할 수 있다.

또 객체에 대한 이질성을 고려하는 어려운 알고리즘들은,
전혀 재참조 되지도 가치가 변하곤 한다. 그래서 가치의 대소관계가 변하기 떄문에 힙에 의한 자료구조도 쉽지 않다.

![[Pasted image 20230925193627.png]]

# 5. LUV - Least Unified Value 알고리즘

본 논문이 제안하는 캐시 교체 알고리즘은
<mark style="background: #FF5582A6;">캐시로 인한 비용 절감 효과를 최대화 시키는 것이 목표이다.</mark>

그러기 위해선 현 시점에서 
1. 참조 가능성이 높고
2. 비용 절감 효과가 큰

객체를 보관하도록 하는 합리적인 객체 평가 방법이 있어야 한다.

이를 위해 참조 가능성을 과거 참조 기록으로 평가하고,
객체들의 비용 차이에 대한 가중치를 곱해 평가하는 알고리즘을 제안한다

Value(i) = H(i) * Weight(i)

- H(i) : 과거 참조 기록에 의한 가치, 
- Weight(i) : 단위 크기당 인출 비용 (c / s)

<mark style="background: #FF5582A6;">캐쉬 용량이 매우 작은 경우엔, 최근 참조 성향을 고려하는 것이 효율적이고, 용량이 클 경우에는 참조 빈도를 함께 고려하는 것이 더욱 효율적인 것으로 알려져 있다.</mark>


웹 캐슁 등의 이질적 특성의 작업 부하나 돌발적인 작업 부하가 존재하는가 존재하는 분산 환경에서는 최근 참조 성향보다 참조 빈도를 고려하는 방법이 더 우수한 성능을 나타내는 것으로 알려져 있다.

이러한 H(i)의 계산은 감소함수 F(x)로 표현할 수 있다.
F(x)는 x시간 이전의 참조에 의한 가치 기여도를 나타내는 함수로,
이 함수에 의해 참조 빈도와 최근 참조 성향의 영향력을 조절할 수 있다.

F(x)는 최근의 참조가 객체의 가치를 높히는데 더욱 도움을 주도록 감소 함수로 정의한다.

H(i) = F(t1) + F(t2) + F(t3) 와 같이 나타낼 수 있다.
그리고 F(x)는 F(x) = (1/2)^(kx)를 사용할 수 있다 (0 <= k <= 1)

## 5.1 LUV의 구현

LUV를 구현할 때, Value 계산 과정에서 과거에 참조 되었던 모든 시각이 사용된다
하지만, 모든 과거 참조 시각을 유지할 경우 저장할 데이터가 너무 많아, 공간 복잡도 측면에서 비현실적인 알고리즘이 되어 버린다.

그리고 Value는 시간의 흐름에 따라 값이 변하므로, 매번 계산해야 할 수도 있는데
그 시간복잡도는 O(n)으로 비현실적이다.

재참조 되는 경우 외엔 Value 값이 변하지 않으므로, Value의 값에 따라 최소 힙을 유지하면 된다.

